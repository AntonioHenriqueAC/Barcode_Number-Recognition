{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Barcode_detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntonioHenriqueAC/tcc/blob/master/google_colab/Barcode_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg3hqNG_O2oM",
        "colab_type": "text"
      },
      "source": [
        "# 1. Baixando as bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DftpArVvN9SK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMwYHpumOky6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install imageai --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uykpeCPPO7Qy",
        "colab_type": "text"
      },
      "source": [
        "# 2. Baixando a CNN pré-treinada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaUgVcHEOvK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "levsKXkSPD6p",
        "colab_type": "text"
      },
      "source": [
        "# 3. Conectando o drive ao colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFUvpxK-Oq7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLEv1PCKPWY4",
        "colab_type": "text"
      },
      "source": [
        "# 4. Carregando os arquivos do colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U350nrD7OtNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Colab/datasets/barcode4.zip\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LexuMVp5Pb1v",
        "colab_type": "text"
      },
      "source": [
        "# 5. Treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqWiwq90OxJ2",
        "colab_type": "code",
        "outputId": "0e586167-1727-4bf9-8b89-ac12ac5cfef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"barcode\")\n",
        "trainer.setTrainConfig(object_names_array=[\"barcode\"], batch_size=4, num_experiments=11, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.85\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  barcode/json/detection_config.json\n",
            "Training on: \t['barcode']\n",
            "Training with Batch Size:  4\n",
            "Number of Experiments:  11\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Training with transfer learning from pretrained Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/11\n",
            "952/952 [==============================] - 886s 930ms/step - loss: 21.8568 - yolo_layer_1_loss: 5.0254 - yolo_layer_2_loss: 5.5363 - yolo_layer_3_loss: 11.2951 - val_loss: 8.8394 - val_yolo_layer_1_loss: 3.8533 - val_yolo_layer_2_loss: 1.3593 - val_yolo_layer_3_loss: 3.6268\n",
            "Epoch 2/11\n",
            "952/952 [==============================] - 859s 903ms/step - loss: 8.4729 - yolo_layer_1_loss: 3.3828 - yolo_layer_2_loss: 1.0691 - yolo_layer_3_loss: 4.0210 - val_loss: 6.1117 - val_yolo_layer_1_loss: 3.9628 - val_yolo_layer_2_loss: 0.8457 - val_yolo_layer_3_loss: 1.3033\n",
            "Epoch 3/11\n",
            "952/952 [==============================] - 858s 901ms/step - loss: 4.9246 - yolo_layer_1_loss: 2.6632 - yolo_layer_2_loss: 0.8932 - yolo_layer_3_loss: 1.3682 - val_loss: 5.5782 - val_yolo_layer_1_loss: 3.4404 - val_yolo_layer_2_loss: 1.1977 - val_yolo_layer_3_loss: 0.9400\n",
            "Epoch 4/11\n",
            "952/952 [==============================] - 859s 902ms/step - loss: 3.9516 - yolo_layer_1_loss: 2.1921 - yolo_layer_2_loss: 0.6851 - yolo_layer_3_loss: 1.0744 - val_loss: 5.6635 - val_yolo_layer_1_loss: 4.2834 - val_yolo_layer_2_loss: 0.5862 - val_yolo_layer_3_loss: 0.7938\n",
            "Epoch 5/11\n",
            "952/952 [==============================] - 866s 910ms/step - loss: 3.5630 - yolo_layer_1_loss: 2.0601 - yolo_layer_2_loss: 0.5917 - yolo_layer_3_loss: 0.9112 - val_loss: 5.5663 - val_yolo_layer_1_loss: 3.7372 - val_yolo_layer_2_loss: 1.2470 - val_yolo_layer_3_loss: 0.5821\n",
            "Epoch 6/11\n",
            "952/952 [==============================] - 862s 906ms/step - loss: 3.3159 - yolo_layer_1_loss: 1.8673 - yolo_layer_2_loss: 0.6075 - yolo_layer_3_loss: 0.8411 - val_loss: 5.0499 - val_yolo_layer_1_loss: 3.5192 - val_yolo_layer_2_loss: 0.7229 - val_yolo_layer_3_loss: 0.8078\n",
            "Epoch 7/11\n",
            "952/952 [==============================] - 865s 909ms/step - loss: 3.0661 - yolo_layer_1_loss: 1.7354 - yolo_layer_2_loss: 0.5287 - yolo_layer_3_loss: 0.8020 - val_loss: 4.2679 - val_yolo_layer_1_loss: 3.3014 - val_yolo_layer_2_loss: 0.5437 - val_yolo_layer_3_loss: 0.4228\n",
            "Epoch 8/11\n",
            "952/952 [==============================] - 860s 903ms/step - loss: 2.7150 - yolo_layer_1_loss: 1.6163 - yolo_layer_2_loss: 0.4146 - yolo_layer_3_loss: 0.6841 - val_loss: 3.6566 - val_yolo_layer_1_loss: 2.7459 - val_yolo_layer_2_loss: 0.3806 - val_yolo_layer_3_loss: 0.5300\n",
            "Epoch 9/11\n",
            "952/952 [==============================] - 859s 902ms/step - loss: 2.6754 - yolo_layer_1_loss: 1.4983 - yolo_layer_2_loss: 0.4505 - yolo_layer_3_loss: 0.7267 - val_loss: 4.3404 - val_yolo_layer_1_loss: 3.2893 - val_yolo_layer_2_loss: 0.4497 - val_yolo_layer_3_loss: 0.6013\n",
            "Epoch 10/11\n",
            "952/952 [==============================] - 858s 901ms/step - loss: 2.6021 - yolo_layer_1_loss: 1.4856 - yolo_layer_2_loss: 0.3951 - yolo_layer_3_loss: 0.7214 - val_loss: 4.3370 - val_yolo_layer_1_loss: 3.1613 - val_yolo_layer_2_loss: 0.4648 - val_yolo_layer_3_loss: 0.7109\n",
            "Epoch 11/11\n",
            "952/952 [==============================] - 856s 899ms/step - loss: 2.5482 - yolo_layer_1_loss: 1.5253 - yolo_layer_2_loss: 0.3956 - yolo_layer_3_loss: 0.6273 - val_loss: 4.5980 - val_yolo_layer_1_loss: 3.0214 - val_yolo_layer_2_loss: 0.9514 - val_yolo_layer_3_loss: 0.6252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msd0qj_DPh3P",
        "colab_type": "text"
      },
      "source": [
        "# 6. Avaliando os modelos gerados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RlpUESXSnfP",
        "colab_type": "code",
        "outputId": "2801ac8b-3220-4811-8cf0-949b25e91c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "metrics = trainer.evaluateModel(model_path=\"barcode/models\", json_path=\"barcode/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Model evaluation....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n",
            "/usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/utils/utils.py:198: RuntimeWarning: overflow encountered in exp\n",
            "  h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
            "/usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/utils/utils.py:197: RuntimeWarning: overflow encountered in exp\n",
            "  w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "skipping the evaluation of barcode/models/detection_model-ex-001--loss-0021.857.h5 because following exception occurred: cannot convert float infinity to integer\n",
            "Model File:  barcode/models/detection_model-ex-002--loss-0008.473.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.4783\n",
            "mAP: 0.4783\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-003--loss-0004.925.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.5783\n",
            "mAP: 0.5783\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-004--loss-0003.952.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.5483\n",
            "mAP: 0.5483\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-005--loss-0003.563.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.6950\n",
            "mAP: 0.6950\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-006--loss-0003.316.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.6556\n",
            "mAP: 0.6556\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-007--loss-0003.066.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.9107\n",
            "mAP: 0.9107\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-008--loss-0002.715.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.8742\n",
            "mAP: 0.8742\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-009--loss-0002.675.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.6963\n",
            "mAP: 0.6963\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-010--loss-0002.602.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.8747\n",
            "mAP: 0.8747\n",
            "===============================\n",
            "Model File:  barcode/models/detection_model-ex-011--loss-0002.548.h5 \n",
            "\n",
            "Using IoU :  0.5\n",
            "Using Object Threshold :  0.3\n",
            "Using Non-Maximum Suppression :  0.5\n",
            "barcode: 0.7423\n",
            "mAP: 0.7423\n",
            "===============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vrORS3j1LJ5m"
      },
      "source": [
        "# 7. Criando pastas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj95LnTcyrHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "path, dirs, files = next(os.walk(\"/content/drive/My Drive/Colab/Corridas\"))\n",
        "file_count_corridas = len(files)\n",
        "print(\"Corridas: \", file_count_corridas + 1)\n",
        "\n",
        "file_count_corridas = file_count_corridas+1\n",
        "newFolderCorrida = file_count_corridas + 1\n",
        "newFolderCorrida = str(newFolderCorrida)\n",
        "folder = \"/content/drive/My\\ Drive/Colab/Corridas/Corrida_\" + newFolderCorrida\n",
        "!mkdir $folder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SGJR89WNLLyl"
      },
      "source": [
        "# 8. Setando as variaveis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ehjz_R1Ixj7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelPath = \"/content/barcode/models/detection_model-ex-008--loss-0002.715.h5\"\n",
        "JsonPath = \"drive/My Drive/Colab/json/detection_config_barcode.json\"\n",
        "InputImage = \"drive/My Drive/Colab/Imagens_Originais/img3.jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_gJfJgSyLGi",
        "colab_type": "text"
      },
      "source": [
        "# 9. Treinando modelo e recortando os codigos de barras da imagem original\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpWqhmsuw7DR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath(modelPath)\n",
        "detector.setJsonPath(JsonPath)\n",
        "detector.loadModel()\n",
        "detections, extracted_objects_array = detector.detectObjectsFromImage(input_image = InputImage, \n",
        "                                                                      output_image_path=\"barcode-detected.jpg\",\n",
        "                                                                      minimum_percentage_probability=10,\n",
        "                                                                      extract_detected_objects=True)\n",
        "def boxPoints(e):\n",
        "  return e['box_points']\n",
        "\n",
        "detections.sort(key=boxPoints)\n",
        "\n",
        "print(\"Número       \" , \": \", \"Porcentagem \", \"      :    \", \"box_points\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "for detection, object_path in zip(detections, extracted_objects_array):\n",
        "    print(detection[\"name\"], \"      : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n",
        "\n",
        "\n",
        "print(\"----------------------------------------------------------------\")\n",
        "print(\"Quantidade de código de barras detectados na imagem: \", len(detections))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4IqY96pDW4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def removeDuplicates():\n",
        "      i=0\n",
        "      soma=0\n",
        "      for detection in detections:\n",
        "        if( i != len(detections)-1 ):\n",
        "            \n",
        "            Xa = (detections[i]['box_points'][0] + detections[i]['box_points'][2])/2\n",
        "            Ya = (detections[i]['box_points'][1] + detections[i]['box_points'][3])/2\n",
        "            Xb = (detections[i+1]['box_points'][0] + detections[i+1]['box_points'][2])/2\n",
        "            Yb = (detections[i+1]['box_points'][1] + detections[i+1]['box_points'][3])/2\n",
        "\n",
        "            Dab = ( (Xb-Xa)**2 + (Yb - Ya)**2 )**1/2\n",
        "            if(Dab < float(10)):\n",
        "                if(detections[i][\"percentage_probability\"] < detections[i+1][\"percentage_probability\"]):\n",
        "                    detections.pop(i)\n",
        "                else:\n",
        "                    detections.pop(i+1)\n",
        "\n",
        "        soma = soma + detections[i][\"percentage_probability\"]\n",
        "        i=i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBueY6086TP4",
        "colab_type": "text"
      },
      "source": [
        "# 10. Movendo as pastas para o diretório correto.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Q4bIO56SVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/barcode-detected.jpg $folder\n",
        "!mv /content/barcode-detected-objects $folder\n",
        "\n",
        "barcode = \"/content/drive/My\\ Drive/Colab/Corridas/Corrida_\" + newFolderCorrida + \"/barcode-detected-objects\"\n",
        "images = \"/content/drive/My\\ Drive/Colab/Corridas/Corrida_\" + newFolderCorrida + \"/images_tags\"\n",
        "!mv  $barcode $images"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}